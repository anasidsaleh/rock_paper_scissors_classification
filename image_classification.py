# -*- coding: utf-8 -*-
"""image_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IHJX6KRImscZA2iN0s3exNBCtrq7B-2x

#**Libraries Installation**
"""

pip install -q tensorflow tensorflow-datasets

"""#**Importing the Libraries**"""

import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
import tensorflow_datasets as tfds 
from tensorflow import keras

"""#**Finding Datasets**"""

tfds.list_builders()

"""#**Get information on the data**"""

builder = tfds.builder('rock_paper_scissors')
info = builder.info
info

"""#**Prepare the data**"""

ds_train = tfds.load('rock_paper_scissors', split='train')
ds_test = tfds.load('rock_paper_scissors', split='test')

"""#**Data viewing**"""

fig = tfds.show_examples(info, ds_train)

"""##**Convert data to numpy format**"""

train_images = np.array([example['image'].numpy()[:,:,0] for example in ds_train])
train_labels = np.array([example['label'].numpy() for example in ds_train])

test_images = np.array([example['image'].numpy()[:,:,0] for example in ds_test])
test_labels = np.array([example['label'].numpy() for example in ds_test])

train_images = train_images.reshape(2520,300, 300, 1)
test_images = test_images.reshape(372,300, 300, 1)

train_images = train_images.astype('float32')
test_images = test_images.astype('float32')

#to make all the values between 0 and 1 (question of performance)
train_images /=255
test_images /=255

train_images

"""#**Trainig the first network**"""

model = keras.Sequential([
                          keras.layers.Flatten(),
                          keras.layers.Dense(512, activation='relu'),
                          keras.layers.Dense(256, activation='relu'),
                          keras.layers.Dense(3, activation='softmax'),
])


model.compile(optimizer='adam',
              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.fit(train_images, train_labels, epochs=10)

print("EVALUATION")
model.evaluate(test_images, test_labels)

"""#**Convolutional Neural Net (CNN) Approach**"""

model = keras.Sequential([
                            keras.layers.Conv2D(64, 3, input_shape=(300,300,1), activation='relu'),
                            keras.layers.Conv2D(32, 3, activation='relu'),
                            keras.layers.Flatten(),
                            keras.layers.Dense(3, activation='softmax')
                              ])

model.compile(optimizer='adam',
              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.fit(train_images, train_labels, batch_size=32, epochs=10)

print("EVALUATION")
model.evaluate(test_images, test_labels)

"""#**Improving our CNN**"""

model = keras.Sequential([
                            keras.layers.AveragePooling2D(6, 3, input_shape=(300,300,1)),
                            keras.layers.Conv2D(64, 3, activation='relu'),
                            keras.layers.Conv2D(64, 3, activation='relu'),
                            keras.layers.MaxPool2D(2,2),
                            keras.layers.Dropout(0.5),
                            keras.layers.Flatten(),
                            keras.layers.Dense(256, activation='relu'),
                            keras.layers.Dense(256, activation='relu'),
                            keras.layers.Dense(3, activation='softmax')
])

model.compile(optimizer='adam',
              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.fit(train_images, train_labels, batch_size=32, epochs=8)

print("EVALUATION")
model.evaluate(test_images, test_labels)

"""#**Using kerastuner to pick best hyperparameters**"""

pip install keras-tuner --upgrade

from kerastuner.tuners import RandomSearch

def build_model(hp):
  model = keras.Sequential()

  model.add(keras.layers.AveragePooling2D(6,3,input_shape=(300,300,1)))

  for i in range(hp.Int("Conv Layers", min_value=0, max_value=3)):
    model.add(keras.layers.Conv2D(hp.Choice(f"layer_{i}_filters", [16,32,64]), 3, activation='relu'))
  
  model.add(keras.layers.MaxPool2D(2,2))
  model.add(keras.layers.Dropout(0.5))
  model.add(keras.layers.Flatten())

  model.add(keras.layers.Dense(hp.Choice("Dense layer", [64, 128, 256, 512, 1024]), activation='relu'))

  model.add(keras.layers.Dense(3, activation='softmax'))

  model.compile(optimizer='adam',
              loss=keras.losses.SparseCategoricalCrossentropy(),
              metrics=['accuracy'])
  
  return model

tuner = RandomSearch(
    build_model,
    objective='val_accuracy',
    max_trials=32,
)

tuner.search(train_images, train_labels, validation_data=(test_images, test_labels), epochs=10, batch_size=32)

best_model = tuner.get_best_models()[0]

best_model.evaluate(test_images, test_labels)

best_model.summary()

tuner.results_summary()

"""#**Save and Load our Models**"""

best_model.save('./models')

loaded_model = keras.models.load_model('./models')

loaded_model.evaluate(test_images, test_labels)

"""#**Plot numpy arrays as images**"""

rgb_images = np.array([example['image'].numpy() for example in ds_train.take(1)])
rgb_image = rgb_images[0]
plt.imshow(rgb_image)
rgb_image.shape

"""#**Use Model to Predict Result for Single Example**"""

result = best_model.predict(np.array([train_images[0]]))
print(result)

predicted_value = np.argmax(result)
print(predicted_value)

"""#**Convert PNG/JPG images to Numpy Format**"""

import imageio

im = imageio.imread('https://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Massachusetts_State_House_-_panoramio_%281%29.jpg/280px-Massachusetts_State_House_-_panoramio_%281%29.jpg')

print(type(im))

im_np = np.asarray(im)

print(im_np.shape)